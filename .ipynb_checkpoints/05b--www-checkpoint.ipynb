{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [05, Part B]: Web services 101\n",
    "\n",
    "The second part of today's lab considers another rich source of data: the web! You will need some of these ideas to do the first homework assignment.\n",
    "\n",
    "References for today's topics:\n",
    "* The `Requests` module: [[docs]](http://requests.readthedocs.org/en/latest/user/quickstart/)\n",
    "* Github's [Web API](https://developer.github.com/v3/)\n",
    "* The `zipfile` module: [[docs]](https://docs.python.org/2/library/zipfile.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Requests module\n",
    "\n",
    "A simple way to download a web page in Python is to use the `Requests` module.\n",
    "\n",
    "The following example downloads the Georgia Tech home page, storing the raw HTML returned as a string named `content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//EN\" \"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\">\n",
      "\n",
      "<\n"
     ]
    }
   ],
   "source": [
    "# Download the Georgia Tech home page\n",
    "\n",
    "import requests\n",
    "response = requests.get ('http://www.gatech.edu')\n",
    "webpage = response.text  # or response.content for raw bytes\n",
    "\n",
    "print (webpage[0:100]) # Prints the first hundred characters only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Exercise: Write some Python code that (a) downloads the class home page, and (b) prints a list of all the \"base filenames\" of IPython notebooks that the page references. The base filename is the name of the file ignoring the preceding path. For instance, the base filename of the notebook you are reading now is, `05b--www`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'01--intro-py', u'02--textproc', u'03--assoc-rules', u'04--comps-gens-sparse']\n"
     ]
    }
   ],
   "source": [
    "# (Enter your code for the preceding exercise in this code box)\n",
    "import requests\n",
    "import re\n",
    "\n",
    "response = requests.get('http://cse6040.gatech.edu/fa15/')\n",
    "webpage = response.text\n",
    "\n",
    "\n",
    "# assert webpage\n",
    "# fileList = []  #initialize\n",
    "# for line in webpage:\n",
    "#     for word in line.split(\" \"):\n",
    "#             #print word\n",
    "#             filePattern = re.compile (\"master+[\\w./-]+\")\n",
    "#             hasFile = filePattern.search (word)\n",
    "#             if hasFile:\n",
    "#                 a = hasFile.start ()\n",
    "#                 b = hasFile.end ()\n",
    "#                 filename = word[a:b]\n",
    "#                 if filename not in fileList:\n",
    "#                     fileList.append(filename)       \n",
    "                \n",
    "#             else:\n",
    "#                 pass\n",
    "# print fileList\n",
    "\n",
    "\n",
    "#p = re.compile(\"master[\\w./-]+\\w.ipynb\")\n",
    "p = re.compile(r\"http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/([0-9][0-9]--[\\w-]+).ipynb\")\n",
    "print p.findall(webpage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Yelp! search.** Here's a more complex example, motivated by a screenshot from Yelp! after executing a search for `ramen` in Atlanta. Take note of the URL.\n",
    "\n",
    "<img src=\"yelp-screenshot.png\">\n",
    "\n",
    "The URL encodes what is known as an _HTTP \"get\" method (or request)_. It basically means a URL with two parts: a _command_ followed by one or more _arguments_. In this case, the command is everything up to and including the word `search`; the arguments are the rest, where individual arguments are separated by the `&` or `#`.\n",
    "\n",
    "> \"HTTP\" stands for \"HyperText Transport Protocol,\" which is a standardized set of communication protocols that allow _web clients_, like your web browser or your Python program, to communicate with _web servers_.\n",
    "\n",
    "In this next example, let's see how to build a \"get request\" with the `requests` module. It's pretty easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Downloading from: 'http://www.yelp.com/search?start=0&ns=1&find_desc=ramen&find_loc=atlanta%2C+ga'\n",
      "\n",
      "==> Excerpt from this URL:\n",
      "\n",
      "<!DOCTYPE HTML>\n",
      "\n",
      "<!--[if lt IE 7 ]> <html xmlns:fb=\"http://www.facebook.com/2008/fbml\" class=\"ie6 ie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_command = 'http://yelp.com/search'\n",
    "url_args = {'find_desc': \"ramen\"\n",
    "            , 'find_loc': \"atlanta, ga\"\n",
    "            , 'ns': 1\n",
    "            , 'start': 0}\n",
    "response = requests.get (url_command, params=url_args)\n",
    "\n",
    "print (\"==> Downloading from: '%s'\" % response.url) # confirm URL\n",
    "print (\"\\n==> Excerpt from this URL:\\n\\n%s\\n\" % response.text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Try modifying and extending the above code to retrieve the 13th entry in the search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (Enter your code for the preceding exercise in this code box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Interacting with a web API\n",
    "\n",
    "We hope the preceding exercise was painful: it is rough downloading raw HTML and trying to extract information from it!\n",
    "\n",
    "Luckily, many websites provide an application programming interface (API) for querying their data or otherwise accessing their services from your programs. For instance, Twitter provides a web API for gathering tweets, Flickr provides one for gathering image data, and Github for accessing information about repository histories.\n",
    "\n",
    "These kinds of web APIs are much easier to use than, for instance, the preceding technique which scrapes raw web pages and then has to parse the resulting HTML. Moreover, there are more scalable in the sense that the web servers can transmit structured data in a less verbose form than raw HTML. In Homework 1, you will apply the techniques below, as well as others, to write some Python scripts to interact with the Yelp! web API.\n",
    "\n",
    "As a starting example, here is some code to look at all the activity on Github related to our course's IPython notebook repository.\n",
    "\n",
    "> Inspect this code and try running it. See if you can figure out what it does. Note that it is split into two parts, so you can try to digest one before moving on to the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'https://api.github.com/users/kindyingjie', u'https://api.github.com/users/rvuduc', u'https://api.github.com/users/ss5211', u'https://api.github.com/users/xiaoyehhuang', u'https://api.github.com/users/omshanti', u'https://api.github.com/users/jiajiechen', u'https://api.github.com/users/amitranshinge', u'https://api.github.com/users/zwan1012', u'https://api.github.com/users/grace828822', u'https://api.github.com/users/shangtse', u'https://api.github.com/users/HeatherMa228', u'https://api.github.com/users/roddtalebi', u'https://api.github.com/users/gokumd', u'https://api.github.com/users/Burn1n9m4n', u'https://api.github.com/users/USofA'])\n"
     ]
    }
   ],
   "source": [
    "response = requests.get ('https://api.github.com/repos/rvuduc/cse6040-ipynbs/events')\n",
    "urls = set ()\n",
    "for event in response.json ():\n",
    "    urls.add (event['actor']['url'])\n",
    "print urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Blank cell, for you to debug or print program state, as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xiaoyehhuang: 'None'\n",
      "amitranshinge: 'Amit Ranshinge'\n",
      "zwan1012: 'None'\n",
      "roddtalebi: 'None'\n",
      "grace828822: 'Grace'\n",
      "rvuduc: 'Rich Vuduc (personal account)'\n",
      "jiajiechen: 'Jiajie \"George\" Chen'\n",
      "gokumd: ''                 ' HI 6040! DONT run your code too many times! You'll reach the rate limit without authentication'\n",
      "ss5211: 'None'\n",
      "USofA: 'None'\n",
      "HeatherMa228: 'None'\n",
      "omshanti: 'None'\n",
      "Burn1n9m4n: 'None'\n",
      "kindyingjie: 'None'\n",
      "shangtse: 'Shang-Tse Chen'\n"
     ]
    }
   ],
   "source": [
    "peeps = {}\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get (url)\n",
    "    key = response.json ()['login']\n",
    "    value = response.json ()['name']\n",
    "    response.close ()\n",
    "    peeps[key] = value\n",
    "    \n",
    "for key, value in peeps.items ():\n",
    "    print (\"%s: '%s'\" % (key, str (value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blank cell, for you to debug or print program state, as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more advanced example: Unpacking a zip file\n",
    "\n",
    "In Labs [4](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/04--comps-gens-sparse.ipynb) and [5-A](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/05a--a-priori-wrap-up.ipynb), you worked with an email repository that you had to manually download and unpack.\n",
    "\n",
    "As it happens, you can do that from within your Python program as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import StringIO\n",
    "\n",
    "URL_ZIPPED = \"http://cse6040.gatech.edu/fa15/skilling-j.zip\"\n",
    "\n",
    "r = requests.get (URL_ZIPPED)\n",
    "zipped_maildir = zipfile.ZipFile (StringIO.StringIO (r.content), 'r')\n",
    "\n",
    "print (\"==> Downloaded: %s\" % URL_ZIPPED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the contents of this archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the first COUNT items in the archive,\n",
    "# print the original and compressed file sizes.\n",
    "\n",
    "COUNT = 10\n",
    "print (\"Contents (first %d items):\" % COUNT)\n",
    "for zi in zipped_maildir.infolist ()[0:COUNT]:\n",
    "    print (\"  %s: %d -> %d bytes\"\n",
    "          % (zi.filename, zi.file_size, zi.compress_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Count messages.** Write a Python program to count the number of messages in the archive.\n",
    "\n",
    "> Hint: How can you tell a folder from a file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_zipped_messages (zipped_maildir):\n",
    "    \"\"\"Returns the number of email messages in a zipped maildir.\"\"\"\n",
    "     # Replace with your implementation\n",
    "\n",
    "msg_count = count_zipped_messages (zipped_maildir)\n",
    "print (\"==> Found %d messages.\" % msg_count)\n",
    "assert msg_count == 4139"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: A-Priori.** Can you adapt your implementation of the a-priori algorithm to work on a zipped email archive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
