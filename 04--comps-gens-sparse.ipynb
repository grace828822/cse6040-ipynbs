{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [04]: List comprehensions, generators, and sparse data structures\n",
    "\n",
    "In our association mining example, recall that we wanted to maintain a _sparse_ table of the number of occurrences of pairs of items. The focus of today's class is on some Python constructs that will enable us to write compact code to build and maintain such a table, specifically for the problem of mining an email corpus for \"co-occurring correspondents.\"\n",
    "\n",
    "Specific topics in today's notebook are:\n",
    "* [List comprehensions](https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions)\n",
    "* [Generators](http://anandology.com/python-practice-book/iterators.html)\n",
    "* [Default dictionaries](https://docs.python.org/2/library/collections.html)\n",
    "* Using the above to build sparse vectors (lists) and sparse matrices (tables) for tabulating item frequencies\n",
    "\n",
    "If all goes well, you will by the end of this notebook implement and test an [A-Priori algorithm from Lab 3](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/03--assoc-rules.ipynb) on a subset of the Enron corpus, available here: http://cse6040.gatech.edu/fa15/enron-maildir-subset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List comprehension\n",
    "\n",
    "By way of review, start by recalling the basic Python idioms for iterating over a list.\n",
    "\n",
    "In particular, suppose you are given a list of words and you wish to create two copies: one in which every word is converted to lowercase and the other to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_list = ['The', 'Quick', 'Brown', 'Fox']\n",
      "lower_list = ['the', 'quick', 'brown', 'fox']\n",
      "upper_list = ['THE', 'QUICK', 'BROWN', 'FOX']\n"
     ]
    }
   ],
   "source": [
    "sample_list = ['The', 'Quick', 'Brown', 'Fox']\n",
    "\n",
    "lower_list = []\n",
    "for x in sample_list:\n",
    "    lower_list.append (x.lower ())\n",
    "    \n",
    "upper_list = []\n",
    "for x in sample_list:\n",
    "    upper_list.append (x.upper ())\n",
    "    \n",
    "print (\"sample_list = %s\" % str (sample_list))\n",
    "print (\"lower_list = %s\" % str (lower_list))\n",
    "print (\"upper_list = %s\" % str (upper_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative idiom: List comprehensions.** The idiom of creating a list by transforming another list is very common. As such, there is a handy compact notation for it, called a _list comprehension_.\n",
    "\n",
    "> Inspect this code and check that it produces the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_list2 = ['the', 'quick', 'brown', 'fox']\n",
      "upper_list2 = ['THE', 'QUICK', 'BROWN', 'FOX']\n"
     ]
    }
   ],
   "source": [
    "lower_list2 = [x.lower () for x in sample_list] # A list comprehension.\n",
    "upper_list2 = [x.upper () for x in sample_list] # Another one!\n",
    "\n",
    "print (\"lower_list2 = %s\" % str (lower_list2))\n",
    "print (\"upper_list2 = %s\" % str (upper_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an analogous concept for constructing a set, which is called a _set comprehension_. A set comprehension constructs a set from an input list or set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'much', 'wood', 'could', 'a', 'woodchuck', 'chuck', 'if', 'a', 'woodchuck', 'could', 'chuck', 'wood']\n",
      "set(['a', 'wood', 'could', 'chuck', 'how', 'much', 'woodchuck', 'if'])\n",
      "['a', 'wood', 'could', 'chuck', 'how', 'much', 'woodchuck', 'if']\n"
     ]
    }
   ],
   "source": [
    "list1 = \"\"\"\n",
    "how much wood could a woodchuck chuck\n",
    "if a woodchuck could chuck wood\n",
    "\"\"\".split ()\n",
    "set_from_list = {x for x in list1}\n",
    "list_from_set = [x for x in set_from_list]\n",
    "\n",
    "print (list1)\n",
    "print (set_from_list)\n",
    "print (list_from_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "\n",
    "You've undoubtedly noticed the common use of `for ... in ...:` constructs in Python programs. The `in` part is quite flexible, allowing you to iterate in a compact and readable way over many kinds of collections.\n",
    "\n",
    "```python\n",
    "# Characters in a string\n",
    "text = 'The quick brown fox jumps over the lazy dog'\n",
    "for letter in text:\n",
    "    ...\n",
    "    \n",
    "# Lists\n",
    "x = ['a', 'b', 'c']\n",
    "for y in x:\n",
    "    ...\n",
    "\n",
    "# Dictionaries\n",
    "x = {'a': 1, 'b': 2, 'c': 3}\n",
    "for key, value in x.items (): # also possible: x.keys(), x.values()\n",
    "    ...\n",
    "\n",
    "# Range objects\n",
    "for i in range (0, 10):\n",
    "    ...\n",
    "\n",
    "# Files (line-by-line)\n",
    "for line in open ('filename.txt', 'r'):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two examples---range objects and files---are especially interesting. They are in fact examples of a special kind of custom iteration that you can design. Here, you'll see an example of one technique called a _generator_.\n",
    "\n",
    "**Generators.** A generator is a special kind of \"interruptible\" function that _yields_ zero or more values or objects. During its execution, a generator may produce an object or value, _temporarily transfer control_ back to the caller with that object or value, and then _resume control_ from the same place when called again. These control transfer points are marked by `yield` statements.\n",
    "\n",
    "For example, suppose you are given a dictionary, and you wish to find all keys whose values match or exceed some threshold. Here is how you might use a generator to do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keys_geq_threshold (Dict, threshold):\n",
    "    \"\"\"\n",
    "    (Generator) Given a dictionary, yields the keys whose values\n",
    "    are at or above (greater than or equal to) a given threshold.\n",
    "    \"\"\"\n",
    "    for key, value in Dict.items ():\n",
    "        if value >= threshold:\n",
    "            yield key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a loop over key-value pairs. However, when a matching key is detected, the function _yields_ control back to the caller. If the caller calls this function again, it will resume after the `yield` statement.\n",
    "\n",
    "You can call such a generator function as part of the `in` statement of a `for` loop to get a sequence of keys. The `range()` and `open()` functions are themselves generators!\n",
    "\n",
    "> Take a look at the code and run it to verify that it produces the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peanuts', 'milk', 'apples']\n"
     ]
    }
   ],
   "source": [
    "inventory = {'apples': 6, 'bananas': 3, 'milk': 5, 'peanuts': 10}\n",
    "\n",
    "# Apply the generator:\n",
    "overstock = [key for key in keys_geq_threshold (inventory, 5)]\n",
    "\n",
    "overstock = []\n",
    "for key in keys_geq_threshold (inventory, 5):\n",
    "    overstock.append(key)\n",
    "\n",
    "print (overstock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Generating email objects\n",
    "\n",
    "To see how generators can be useful, let's return to the problem of mining an email archive.\n",
    "\n",
    "**(Review) Parsing an email.** First, recall that Python has an `email` module, which you can use to parse plaintext emails.\n",
    "\n",
    "> As a minor technical aside, these emails should be formatted according to the [RFC 822 standard](http://www.w3.org/Protocols/rfc822/).\n",
    "\n",
    "Given a string formatted in such a way, you can create a structured _email object_. You can then query the object to extract fields of the email, like the sender, the recipient, the date, the subject, or the body, among others.\n",
    "\n",
    "> Here is some sample code to look for email addresses in certain fields of the email; run it to see that it produces the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email addresses found: set(['junk@vuduc.org', 'jebby@mindsprang.com', 'prez@whitehouse.gov', 'richie@cc.gatech.edu'])\n"
     ]
    }
   ],
   "source": [
    "email_msg_text = \"\"\"Message-ID: aslkj42t90wdk23o5uxc@jinx\n",
    "Date: Tue Aug 25 23:44:06 EDT 2015\n",
    "From: Richard (Rich) Vuduc <richie@cc.gatech.edu>\n",
    "To: Jebediah Springfield <jebby@mindsprang.com>\n",
    "Reply-To: junk@vuduc.org\n",
    "Subject: Spam -- delete me\n",
    "\n",
    "Please read the subject, or reply me at prez@whitehouse.gov or junk@vuduc.org\n",
    "\n",
    "Thanks,\n",
    "\n",
    "-- Rich\"\"\"\n",
    "\n",
    "import email.parser\n",
    "import re\n",
    "\n",
    "#regular expression\n",
    "EMAIL_PATTERN = re.compile(\"[\\w.+]+@[\\w.]+\")\n",
    "\n",
    "# Parses email text into an object\n",
    "email_msg_obj = email.parser.Parser ().parsestr (email_msg_text)\n",
    "\n",
    "\n",
    "# Poke around for email addresses in the From, To, Reply-To, and body:\n",
    "addrs = set (EMAIL_PATTERN.findall (email_msg_obj['From']))\n",
    "addrs.update (EMAIL_PATTERN.findall (email_msg_obj['Reply-To']))\n",
    "addrs.update (EMAIL_PATTERN.findall (email_msg_obj['To']))\n",
    "addrs.update (EMAIL_PATTERN.findall (email_msg_obj.get_payload ()))\n",
    "\n",
    "print (\"Email addresses found: %s\" % str (addrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the code above calls,\n",
    "\n",
    "```python\n",
    "    ... email.parser.Parser ().parsestr (email_msg_text)\n",
    "```\n",
    "\n",
    "There is another handy function, `parse (email_file_obj)`, that does the same thing except that it reads the email contents from a file instead of a string.\n",
    "\n",
    "**Email directories (`maildir`).** Next, let's introduce the concept of an _email directory_, or a `maildir` for short. A `maildir` is any directory that contains any number of nested subdirectories and files, where each file is an email message.\n",
    "\n",
    "> Here is a generator to produce email objects for every message in a `maildir`. Take a look and make sure you understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4139"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def messages (maildir_root):\n",
    "    \"\"\"\n",
    "    (Generator) Given a mailbox directory name, yields an\n",
    "    email object for each message therein.\n",
    "    \"\"\"\n",
    "    for base, dirs, files in os.walk (maildir_root):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join (base, filename)\n",
    "            email_file = open (filepath)\n",
    "            msg = email.parser.Parser ().parse (email_file)\n",
    "            email_file.close ()\n",
    "            yield msg\n",
    "\n",
    "a = [c for c in messages('./enron-maildir-subset/skilling-j' )]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Now it's your turn!\n",
    "\n",
    "As part of this exercise, you should download and unpack the sample `maildir` available here, which is a subset of the full Enron corpus: http://cse6040.gatech.edu/fa15/enron-maildir-subset.zip\n",
    "\n",
    "> Given the `messages()` generator, complete the function, `count_messages ()`, so that it returns the number of messages in a `maildir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 1:Found 4139 messages.\n",
      "Sol 2:Found 4139 messages.\n"
     ]
    }
   ],
   "source": [
    "# Your task: Complete this function!\n",
    "import os\n",
    "\n",
    "def count_messages (maildir_root): #Returns the # of messages stored in a given mailbox directory.\n",
    "    count = 0\n",
    "    for msg in messages('./enron-maildir-subset/skilling-j' ):\n",
    "            count = count +1\n",
    "    return count\n",
    "\n",
    "def count_messages1(maildir_root):   #Using more memory because\n",
    "    a = [msg for msg in messages('./enron-maildir-subset/skilling-j' )]\n",
    "    return len(a)\n",
    "\n",
    "\n",
    "# Our testing code:\n",
    "MAILDIR = './enron-maildir-subset/skilling-j' # Change path if needed\n",
    "ANSWER = 4139\n",
    "\n",
    "num_msgs = count_messages (MAILDIR)\n",
    "print (\"Sol 1:Found %d messages.\" % num_msgs)\n",
    "\n",
    "num_msgs1 = count_messages (MAILDIR)\n",
    "print (\"Sol 2:Found %d messages.\" % num_msgs1)\n",
    "assert num_msgs == ANSWER  # The answer for the above maildir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default dictionaries: `collections.defaultdict`\n",
    "\n",
    "The next new concept you will explore is a twist on the usual dictionary object, which is a _default dictionary_.\n",
    "\n",
    "To motivate it, consider the following common pattern.\n",
    "\n",
    "Suppose you are given a string and you wish to count the number of occurrences of alphabetic characters. A first and natural way might be to scan the string letter by letter, using a dictionary to store the counts. This approach would then involve a common idiom: for each letter, check whether we created a dictionary entry already; if so, then update the entry; otherwise, create a new entry.\n",
    "\n",
    "> Inspect this example and try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'c': 11, 'd': 6, 'f': 1, 'i': 1, 'h': 6, 'k': 4, 'm': 1, 'l': 2, 'o': 11, 'u': 7, 'w': 5}\n",
      "\n",
      "(Passed a quick, partial test.)\n"
     ]
    }
   ],
   "source": [
    "def alpha_chars (text):\n",
    "    \"\"\"\n",
    "    (Generator) Yields each of the alphabetic characters in a string.\n",
    "    \"\"\"\n",
    "    for letter in text:\n",
    "        if letter.isalpha ():\n",
    "            yield letter\n",
    "            \n",
    "            \n",
    "# Example: Count letter frequencies (case-insensitive), take 1\n",
    "text = \"\"\"How much wood could a woodchuck chuck\n",
    "if a woodchuck could chuck wood?\"\"\"\n",
    "\n",
    "freqs1 = {} # Frequency table for method 1\n",
    "\n",
    "for letter in alpha_chars (text.lower ()):\n",
    "    if letter in freqs1:\n",
    "        freqs1[letter] += 1\n",
    "    else:\n",
    "        freqs1[letter] = 1\n",
    "        \n",
    "print (freqs1)\n",
    "\n",
    "# Quick check\n",
    "assert freqs1['o'] == 11 and freqs1['h'] == 6\n",
    "print (\"\\n(Passed a quick, partial test.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it happens, we can express the same pattern in a slightly more compact notation using a special form of a dictionary called a _default dictionary_, which is defined in Python's `collections` module.\n",
    "\n",
    "Here is an example of what it would look like. Notice that it obviates the explicit conditional to test for the presence of an existing key!\n",
    "\n",
    "> Q: Inspect this code. Notice that the `defaultdict()` call takes an argument. Why might such an argument be needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'a': 2, 'c': 11, 'd': 6, 'f': 1, 'i': 1, 'h': 6, 'k': 4, 'm': 1, 'l': 2, 'o': 11, 'u': 7, 'w': 5})\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "(Passed: Method 2 gives the same answer as method 1.)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Frequency table, take 2\n",
    "freqs2 = defaultdict (int) # take note of argument, `int` and defualt with 0\n",
    "\n",
    "for letter in alpha_chars (text.lower ()):\n",
    "    freqs2[letter] += 1\n",
    "    \n",
    "print (freqs2)\n",
    "print (\"\\n\")\n",
    "print (int()) #have default with 0\n",
    "\n",
    "# Check answers against the first method\n",
    "for key, value in freqs1.items (): assert freqs2[key] == value\n",
    "for key, value in freqs2.items (): assert freqs1[key] == value\n",
    "print (\"\\n(Passed: Method 2 gives the same answer as method 1.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercse: Sparse matrices.** This exercise is a kind of test to see whether you understand how default dictionaries work.\n",
    "\n",
    "First, let's \"package up\" the above example into an abstract data type, which is a _sparse (integer) vector_.\n",
    "\n",
    "> Inspect and try this example, to confirm it gives the same results as the preceding examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparse_vector ():\n",
    "    return defaultdict (int)\n",
    "\n",
    "def print_sparse_vector (x):\n",
    "    for key, value in x.items ():\n",
    "        print (\"%s: %d\" % (key, value))\n",
    "        \n",
    "letter_freqs = sparse_vector ()\n",
    "for letter in alpha_chars (text.lower ()):\n",
    "    letter_freqs[letter] += 1\n",
    "    \n",
    "print_sparse_vector (letter_freqs)\n",
    "for key, value in freqs2.items (): assert letter_freqs[key] == value\n",
    "for key, value in letter_freqs.items (): assert freqs2[key] == value\n",
    "print (\"\\n(Passed check against method 2.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we instead want to compute how frequently _pairs_ of letters occur within words. Instead of a sparse vector, you might instead maintain a table, or _sparse matrix_, such that the $(i, j)$ entry of the matrix counts the number of times the letters $i$ and $j$ co-occur within a word.\n",
    "\n",
    "> Complete the code below to implement a sparse matrix that counts the number of times that a pair of letters co-occurs in a word. In particular, fill in the code for `sparse_matrix()` and `alpha_chars_pairs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# === COMPLETE THIS FUNCTION ===\n",
    "# Hint: See the definition of `print_sparse_matrix()`\n",
    "# to see the interface to which your sparse matrix object\n",
    "# should conform.\n",
    "def sparse_matrix ():\n",
    "    \"\"\"\n",
    "    Returns an empty sparse matrix that can hold integer counts\n",
    "    of pairs of elements.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def print_sparse_matrix (x):\n",
    "    for i, row_i in x.items ():\n",
    "        for j, value in row_i.items ():\n",
    "            print (\"[%s, %s]: %d\" % (i, j, value))\n",
    "            \n",
    "            \n",
    "# === COMPLETE THIS FUNCTION ===\n",
    "# Hint: Look at how this function is used, below.\n",
    "def alpha_chars_pairs (text):\n",
    "    \"\"\"\n",
    "    (Generator) Yields every one of the 4-choose-2 pairs of\n",
    "    'positionally distinct' alphabetic characters in a string.\n",
    "    \n",
    "    That is, each position of the string is regarded as distinct,\n",
    "    but the pair of characters coming from positions (i, j),\n",
    "    where i != j, are considered the \"same\" as the paired\n",
    "    positions (j, i). Non-alphabetic characters should be\n",
    "    ignored.\n",
    "    \n",
    "    For instance, `alpha_chars_pairs (\"te3x_t\")` should produce\n",
    "    has just 4 positionally distinct characters, so this routine\n",
    "    should return the 4 choose 2 == 6 pairs:\n",
    "      ('t', 'e')    <-- from positions (0, 1)\n",
    "      ('t', 'x')    <-- from positions (0, 3)\n",
    "      ('t', 't')    <-- from positions (0, 5)\n",
    "      ('e', 'x')    <-- from positions (1, 3)\n",
    "      ('e', 't')    <-- from positions (1, 5)\n",
    "      ('x', 't')    <-- from positions (3, 5)\n",
    "    \"\"\"\n",
    "    pass\n",
    "            \n",
    "\n",
    "# === Testing code follows ===\n",
    "\n",
    "# Compute frequency of pairs of positionally distinct,\n",
    "# case-insensitive alphabetic characters in a word.\n",
    "letter_pair_counts = sparse_matrix ()\n",
    "words = text.split ()\n",
    "for word in words:\n",
    "    for w_i, w_j in alpha_chars_pairs (word.lower ()):\n",
    "        # Enforce convention: w_i < w_j\n",
    "        w_i, w_j = min (w_i, w_j), max (w_i, w_j)\n",
    "        letter_pair_counts[w_i][w_j] += 1\n",
    "\n",
    "print (\"Text: '%s'\" % text)\n",
    "print (\"\\n==> Frequencies:\")\n",
    "print_sparse_matrix (letter_pair_counts)\n",
    "assert letter_pair_counts['c']['c'] == 4\n",
    "assert letter_pair_counts['h']['o'] == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: The A-Priori algorithm\n",
    "\n",
    "> Using all of the preceding material, implement the _A-Priori_ algorithm from the [previous Lab 3 notebook](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/03--assoc-rules.ipynb) to detect frequent email correspondents.\n",
    "\n",
    "You may make the following simplifying assumptions, which may or may not be valid depending on what the true analysis end-goal is.\n",
    "* You need only examine the 'From:' and 'To:' fields of an email message. Ignore all other fields.\n",
    "* You should only \"count\" an email address if _both_ the 'From:' and 'To:' fields are set. Otherwise, you cannot tell from whom the message was sent or who is the recipient, and may therefore ignore the interaction.\n",
    "* Consider pairs that consist of a sender and a recipient. In other words, do not match multiple recipients of a single message as a \"pair.\"\n",
    "* Ignore the direction of the exchange. That is, regard `bob@gatech.edu` sending to `kate@aol.com` as the same pair as `kate@aol.com` sending to `bob@gatech.edu`.\n",
    "\n",
    "> For Jeffrey Skilling's `maildir` and a threshold of 65 or more co-occurrences, our solution finds **10** frequently corresponding pairs. For the full data set, it finds **140** pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify maildir location; you may need to update these paths.\n",
    "MAILDIR = 'enron-maildir-subset/skilling-j' # Skilling's mail only\n",
    "#MAILDIR = 'enron-maildir-subset' # Full subset\n",
    "\n",
    "# Specify the minimum number of occurrences to be considered \"frequent\"\n",
    "THRESHOLD = 65\n",
    "\n",
    "# === FILL-IN YOUR IMPLEMENTATION AND TEST CODE BELOW ==\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
